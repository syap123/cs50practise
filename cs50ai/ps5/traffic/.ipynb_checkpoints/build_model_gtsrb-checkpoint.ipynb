{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_WIDTH = 30\n",
    "IMG_HEIGHT = 30\n",
    "NUM_CATEGORIES = 43\n",
    "TEST_SIZE = 0.4\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Check command-line arguments\n",
    "    if len(sys.argv) not in [2, 3]:\n",
    "        sys.exit(\"Usage: python traffic.py data_directory [model.h5]\")\n",
    "\n",
    "    # Get image arrays and labels for all image files\n",
    "    images, labels = load_data(sys.argv[1])\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # Get a compiled neural network\n",
    "    model = get_model()\n",
    "\n",
    "    # Fit model on training data\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
    "\n",
    "    # Evaluate neural network performance\n",
    "    model.evaluate(x_test,  y_test, verbose=2)\n",
    "    print(classification_report(np.argmax(y_test, axis=1), y_pred))\n",
    "    # Save model to file\n",
    "    if len(sys.argv) == 3:\n",
    "        filename = sys.argv[2]\n",
    "        model.save(filename)\n",
    "        print(f\"Model saved to {filename}.\")\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load image data from directory `data_dir`.\n",
    "\n",
    "    Assume `data_dir` has one directory named after each category, numbered\n",
    "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
    "    number of image files.\n",
    "\n",
    "    Return tuple `(images, labels)`. `images` should be a list of all\n",
    "    of the images in the data directory, where each image is formatted as a\n",
    "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
    "    be a list of integer labels, representing the categories for each of the\n",
    "    corresponding `images`.\n",
    "    \"\"\"\n",
    "    #first set required dimension\n",
    "    required_dimension = (IMG_WIDTH,IMG_HEIGHT)\n",
    "\n",
    "    #now loop through every input file\n",
    "    labels = []\n",
    "    images = []\n",
    "    for root, subdirectories, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            split_path = path.split(os.sep)\n",
    "            # if subdirectory not an integer, just skip\n",
    "            label = split_path[-2]\n",
    "            try:\n",
    "                int(label)\n",
    "            except:\n",
    "                continue\n",
    "            # get image into array format\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.resize(image,required_dimension)\n",
    "            image = image / 255.0\n",
    "            labels.append(label)\n",
    "            images.append(image)\n",
    "\n",
    "    return (images,labels)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model. Assume that the\n",
    "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
    "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
    "    \"\"\"\n",
    "\n",
    "    # usually I use a notebook to record all my attempts, but since I do this too often at my job, I will not write a beautiful report as practise\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "    # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, 3, activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "    ),\n",
    "\n",
    "    # Max-pooling layer, using 2x2 pool size\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64, 3, activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "    ),    \n",
    "    #tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten units\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Add a hidden layer with dropout\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.1),  \n",
    "\n",
    "    #tf.keras.layers.Dense(1280, activation=\"relu\"),\n",
    "    #tf.keras.layers.Dropout(0.2),  \n",
    "\n",
    "\n",
    "    # Add an output layer with output units for all 10 digits\n",
    "    tf.keras.layers.Dense(43, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Train neural network\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26640\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 2.1604 - accuracy: 0.4354\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 0.2955 - accuracy: 0.9164\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 12s 24ms/step - loss: 0.1362 - accuracy: 0.9625\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 12s 25ms/step - loss: 0.0964 - accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 14s 27ms/step - loss: 0.0635 - accuracy: 0.9811\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 12s 25ms/step - loss: 0.0513 - accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 12s 25ms/step - loss: 0.0458 - accuracy: 0.9863\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 12s 25ms/step - loss: 0.0383 - accuracy: 0.9877\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 13s 25ms/step - loss: 0.0438 - accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 12s 25ms/step - loss: 0.0208 - accuracy: 0.9941\n",
      "333/333 - 2s - loss: 0.0941 - accuracy: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        63\n",
      "           1       0.99      0.96      0.97       622\n",
      "           2       0.99      0.94      0.97       617\n",
      "           3       0.96      0.96      0.96       381\n",
      "           4       0.95      1.00      0.97       523\n",
      "           5       0.94      0.97      0.95       531\n",
      "           6       0.99      1.00      1.00       119\n",
      "           7       0.97      0.99      0.98       383\n",
      "           8       0.97      0.98      0.98       399\n",
      "           9       1.00      0.98      0.99       368\n",
      "          10       1.00      1.00      1.00       521\n",
      "          11       0.97      0.99      0.98       353\n",
      "          12       0.98      1.00      0.99       569\n",
      "          13       1.00      0.99      0.99       565\n",
      "          14       1.00      0.97      0.99       214\n",
      "          15       0.98      0.99      0.98       169\n",
      "          16       0.99      0.99      0.99       114\n",
      "          17       0.95      0.99      0.97       297\n",
      "          18       0.99      0.99      0.99       317\n",
      "          19       0.95      0.95      0.95        60\n",
      "          20       0.98      0.98      0.98        99\n",
      "          21       0.99      0.99      0.99        87\n",
      "          22       0.95      1.00      0.97       107\n",
      "          23       0.99      0.95      0.97       150\n",
      "          24       1.00      0.91      0.95        77\n",
      "          25       1.00      0.98      0.99       406\n",
      "          26       0.94      0.97      0.95       161\n",
      "          27       1.00      0.94      0.97        71\n",
      "          28       0.99      0.99      0.99       147\n",
      "          29       0.92      0.93      0.93        73\n",
      "          30       1.00      0.95      0.97       119\n",
      "          31       0.99      0.99      0.99       202\n",
      "          32       0.97      1.00      0.99        68\n",
      "          33       0.98      1.00      0.99       208\n",
      "          34       1.00      0.97      0.98       123\n",
      "          35       0.99      0.99      0.99       333\n",
      "          36       1.00      0.97      0.98        96\n",
      "          37       1.00      0.97      0.99        75\n",
      "          38       1.00      1.00      1.00       544\n",
      "          39       1.00      1.00      1.00        79\n",
      "          40       0.96      0.99      0.97        96\n",
      "          41       1.00      0.96      0.98        74\n",
      "          42       0.97      0.99      0.98        76\n",
      "\n",
      "    accuracy                           0.98     10656\n",
      "   macro avg       0.98      0.98      0.98     10656\n",
      "weighted avg       0.98      0.98      0.98     10656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_data(\"./gtsrb/\")\n",
    "print(len(labels))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "labels = tf.keras.utils.to_categorical(labels)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    ")\n",
    "\n",
    "# Get a compiled neural network\n",
    "model = get_model()\n",
    "\n",
    "# Fit model on training data\n",
    "model.fit(x_train, y_train, epochs=EPOCHS)\n",
    "\n",
    "# Evaluate neural network performance\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cfx_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred, labels = [x for x in range(0,43)])\n",
    "\n",
    "pd.DataFrame(cfx_matrix).to_csv(\"cfx4.csv\")\n",
    "#cfx_matrix.tofile('cfx_matrix.csv',sep=',')\n",
    "\n",
    "#np.savetxt(\"confusion_matrix.csv\", a, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56,   9,   0, ...,   0,   0,   0],\n",
       "       [  1, 571,   6, ...,   0,   0,   0],\n",
       "       [  0,  20, 568, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 101,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,  59,   2],\n",
       "       [  0,   0,   0, ...,   0,   0,  84]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_test, axis=1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 12, 30, ..., 23, 15, 15])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    labels = []\n",
    "    images = []\n",
    "    required_dimension = (IMG_WIDTH,IMG_HEIGHT)\n",
    "    for root, subdirectories, files in os.walk(\"./gtsrb/\"):\n",
    "        print(files)\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            path = os.path.join(root, file)\n",
    "            split_path = path.split(os.sep)\n",
    "            # if subdirectory not an integer, just skip\n",
    "            label = split_path[-2]\n",
    "            try:\n",
    "                int(label)\n",
    "            except:\n",
    "                continue\n",
    "            # get image into array format\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.resize(image,required_dimension)\n",
    "            image = image / 255.0\n",
    "            labels.append(label)\n",
    "            images.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.walk(\"./gtsrb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
